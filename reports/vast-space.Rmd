---
title: "Exploring S and N space"
output: github_document
date: 10/8/2019
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(drake)
library(dplyr)
library(ggplot2)
library(scads)
```

## Combinations of S & N

These are the combinations of S and N I ran sampling on. There are three chunks: small, large S, and large N. Small is to get at behavior for very small S and N. Large S and large N explore larger communities in those directions. The bottom right corner is gently constrained because N must be >= to S. I tried to explore the general regions of space filled by the datasets in the Baldridge/White papers. I've done this edges-approach because is computationally expensive to explore the large S-large N corner, and there aren't datasets there. 

```{r S and N combos}

small_s <- c(2:10)
small_n <-  c(2:19, seq(20, 200, by = 10))

small_combinations <- expand.grid(S = small_s, N = small_n) %>%
  dplyr::filter(N > S)

large_s <- c(10, 20, 30, seq(50, 250, by = 50))
moderate_n <- seq(50, 250, by = 50)

ls_mn_combinations <- expand.grid(S = large_s, N = moderate_n) %>%
  dplyr::filter(N > S)

moderate_s <- c(seq(5, 40, by = 5), 50, 75)
large_n <- c(seq(500, 2500, by = 500), 5000, 7500)

ms_ln_combinations <- expand.grid(S = moderate_s, N = large_n) %>%
  dplyr::filter(N > S)

all_combinations <- dplyr::bind_rows(small = small_combinations, large_s = ls_mn_combinations, large_n= ms_ln_combinations, .id = "source") %>%
  mutate(source = as.factor(source))

combinations_plot <- ggplot(data = all_combinations, aes(x = S, y = N, color = source)) +
  geom_point() +
  theme_bw() +
  scale_color_viridis_d(end = .8)

combinations_plot

combinations_plots_zoomed <- combinations_plot +
  facet_wrap(~source, strip.position = "top", scales = "free")
combinations_plots_zoomed
```

```{r cache}

## Set up the cache and config
db <- DBI::dbConnect(RSQLite::SQLite(), here::here("drake", "drake-cache.sqlite"))
cache <- storr::storr_dbi("datatable", "keystable", db)

```

```{r cached objects manip, eval = F}
cached_fs <- cached(cache=cache) [which(substr(cached(cache=cache), 0, 2) == "fs")]
fs_S <- vapply(as.matrix(cached_fs), FUN = function(aword) return(as.integer(unlist(strsplit(aword, "_")[[1]][[2]]))), FUN.VALUE = 10)
fs_N <- vapply(as.matrix(cached_fs), FUN = function(aword) return(as.integer(unlist(strsplit(aword, "_")[[1]][[3]]))), FUN.VALUE = 10)

fs_lookup <- data.frame(sn_combination = cached_fs, S = fs_S, N = fs_N, stringsAsFactors = F)

cached_di <- cached(cache=cache) [which(substr(cached(cache=cache), 0, 2) == "di")]
di_S <- vapply(as.matrix(cached_di), FUN = function(aword) return(as.integer(unlist(strsplit(aword, "_")[[1]][[3]]))), FUN.VALUE = 10)
di_N <- vapply(as.matrix(cached_di), FUN = function(aword) return(as.integer(unlist(strsplit(aword, "_")[[1]][[4]]))), FUN.VALUE = 10)
di_lookup <- data.frame(sn_combination = cached_di, S = di_S, N = di_N, stringsAsFactors = F)


fs_list <- lapply(as.matrix(cached_fs), FUN = readd, character_only = T, cache = cache)
names(fs_list) <- cached_fs
di_list <- lapply(as.matrix(cached_di), FUN = readd, character_only = T, cache = cache)
names(di_list) <- cached_di

fs_df <- bind_rows(fs_list, .id = "sn_combination") %>%
  left_join(fs_lookup, by = "sn_combination")
di_df <- bind_rows(di_list, .id = "sn_combination") %>%
  left_join(di_lookup, by = "sn_combination")

rm(fs_list)
rm(di_list)
rm(cached_fs)
rm(cached_di)

write.csv(fs_df, file = here::here("drake", "fs_df.csv"))

write.csv(di_df, file = here::here("drake", "di_df.csv"))


```



## Number of unique elements (out of 10,000 draws)

I've drawn 10,000 times from the feasible set for each of these S-N combinations. For some of them, we won't be able to get 10,000 unique elements from the feasible set because the FS is in fact much smaller than that. 

```{r unique draws}
di_df <- read.csv(here::here("drake", "di_df.csv"), stringsAsFactors = F)

ndraws <- di_df %>%
  select(S, N, sim) %>%
  distinct() %>%
  group_by(S, N) %>%
  summarize(nsamples = n()) %>%
  ungroup() %>%
  mutate(log_nsamples = log(nsamples)) %>%
  left_join(all_combinations, by = c("S", "N"))

ndraws_plot <- ggplot(data = ndraws, aes(x = S, y = N, color = log_nsamples)) +
  geom_point(alpha = .6) +
  theme_bw() +
  scale_color_viridis_c(end = .8, direction = -1, option = "magma")

ndraws_plot

ndraws_plot_zoomed <- ndraws_plot +
  facet_wrap(~source, strip.position = "top", scales = "free")
ndraws_plot_zoomed


```

## Shapes represented

### Skewness

```{r skewness min, max, range plot, fig.width = 15, fig.height = 5} 

di_df_M <- di_df %>%
  group_by(sn_combination, source, S, N) %>%
  summarize_at(.vars = c("skew", "shannon", "simpson"), .funs = list("min" = min, "max" = max, "sd" = sd, "mean" = mean)) %>%
  ungroup() %>%
  mutate(
    shannon_range = shannon_max - shannon_min,
    simpson_range = simpson_max - simpson_min,
    skew_range = skew_max - skew_min
  ) %>%
  tidyr::gather(-sn_combination, -source, -S, -N, key = "variable", value = "val")

range_plots <- lapply(as.matrix(c("skew_range", "simpson_range", "shannon_range")), FUN = function(var_name) 
  return(ggplot(data = filter(di_df_M, variable  == var_name), aes(x =S, y = N, color = val)) +
           geom_point() +
           theme_bw() +
           scale_color_viridis_c(end = .8, option = "magma") +
           ggtitle(var_name))
)

gridExtra::grid.arrange(grobs = range_plots, nrow = 1)
```



### Shannon

### Simpson

## Some sample heatmaps?

### Small communities

```{r small heatmap}

loadd(fs_3_9_10000_master_p_table, cache = cache)
tiny_plot <- ggplot(data = fs_3_9_10000_master_p_table, aes(x =rank, y = abund, color = as.factor(sim))) +
  geom_line(alpha = .7, aes(group = sim)) +
  theme_bw() +
  ggtitle("S = 3, N = 9")
tiny_plot

loadd(fs_7_40_10000_master_p_table, cache = cache)

small_plot <- ggplot(data = fs_7_40_10000_master_p_table, aes(x =rank, y = abund)) +
  geom_point(alpha = .05) +
  theme_bw() +
  ggtitle("S = 7, N = 40")

small_plot

```

### Large S, moderate N

```{r large s med N}
loadd(fs_100_200_10000_master_p_table, cache = cache)

largeS_plot <- ggplot(data = filter(fs_100_200_10000_master_p_table, sim < 1000), aes(x =rank, y = abund)) +
  geom_point(alpha = .01) +
  theme_bw() +
  ggtitle("S = 100, N = 200")

largeS_plot
```

### Large N, moderate S

```{r large n med S}

loadd(fs_30_5000_10000_master_p_table, cache = cache)

largeN_plot <- ggplot(data = filter(fs_30_5000_10000_master_p_table, sim < 1000), aes(x =rank, y = abund)) +
  geom_point(alpha = .01) +
  theme_bw() +
  ggtitle("S = 30, N = 5000")

largeN_plot

```